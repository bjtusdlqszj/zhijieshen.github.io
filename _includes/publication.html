<head>
	<style>
		body{
			color: #333;
		}
		#container{
			min-width: 1000px;
			width: 1000px;
/*			overflow: auto;
*/			margin: 50px auto;padding: 30px;
			/*zoom: 1;*/
*//*			border: 1px solid #ccc;background: #fc9;color: #fff;
*/		}
		#left{
			float: left;
			width: 400px;
			height: 230px;
			margin-left: 0px;
		}
		#right{
			float: left;
			width: auto;
			margin-left: 50px;
		}
		#name{
			font-size: 22.0pt;
		    mso-bidi-font-size: 24.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		        font-weight: bold;
		}
		#info{
		    font-size: 16.0pt;
		    mso-bidi-font-size: 17.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    margin-top: 30px;
		    margin-left: 5px;
		    margin-bottom: 10px;
		    
		}
		.clear{clear:both; height: 0; line-height: 0; font-size: 0}
		.Bio{
			font-size:16.0pt;
			mso-bidi-font-size:17.0pt;
			line-height:150%;
			font-family:Times;
			mso-bidi-font-family:Lato-Regular;
			text-align: justify;
		}
		span.SpellE {
		    mso-style-name: "";
		    mso-spl-e: yes;
		}
		span.Title{
			    font-size: 22.0pt;
			    mso-bidi-font-size: 17.0pt;
			    font-family: Times;
			    mso-bidi-font-family: Lato-Regular;
			    font: bold;
			    margin-top: 10px;
		}
		div.section{
			padding-top: 30px;
		}
		
		div.sub-left{
			float: left;
			width: 250px;
						
		}
		div.sub-left img{
			vertical-align: middle;
			horizontal-align: middle;
			margin-top: 10px;
		}
		
		div.sub-left span{
			height: 100%;
			display: inline-block;
			vertical-align: top;
						
		}
		div.sub-right{
			float: left;
			width: 700px;			
		}
		.paper{
			overflow: auto;
			zoom:1;
			padding-bottom: 0px;
			min-height: 150px;

		}
		.paperTitle{
			font-size:14.0pt;
			mso-bidi-font-size:18.0pt;
			font-family:Times;
			mso-bidi-font-family:Times;
			margin-top: 10px;
			margin-bottom: 10px;
			font-weight: bold;
		}
		.paperName,.paperPub{
		    font-size: 12.0pt;
		    mso-bidi-font-size: 13.0pt;		    
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    line-height:150%;
		}
		.link{
		    font-size: 12.0pt;
		    mso-bidi-font-size: 13.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    margin-top: 10px;
		    margin-bottom: 0px;
		}
		.special{
		    margin-top: 0in;
		    margin-bottom: 0in;
		    margin-left: -.9pt;
		    margin-bottom: .0001pt;
		    text-indent: .9pt;
		    mso-pagination: none;
		    tab-stops: 13.75in;
		    mso-layout-grid-align: none;
		    text-autospace: none;
		}
		.long div.sub-left, .long div.sub-right{
			height: 300px;
			width: 950px;

		}
		.short div.sub-left, .short div.sub-right{
			height:160px;

		}
		div.sub-left,div.sub-right{
			height:200px;

		}
	</style>
</head>


<h3>
	<a name='publications'></a> Publications
</h3>

<h4>
	<a name='pre'></a> Preprint
</h4>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/panoformer.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>PanoFormer: Panorama Transformer for Indoor 360Â° Depth Estimation</strong><br />
					   Zhijie Shen, Chunyu Lin, <strong>Kang Liao</strong>, Lang Nie, Zishuo Zheng, Yao Zhao<br />
					   <a href="https://arxiv.org/pdf/2203.09283.pdf">[arXiv]</a>
					   <a href="">[Github]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

<h4>
	<a name='2022'></a> 2022
</h4>

<h4>
	<a name='2021'></a> 2021
</h4>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/ICCV21-curriculum.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Multi-Level Curriculum for Training A Distortion-Aware Barrel Distortion Rectification Model</strong><br />
					  <strong>Kang Liao</strong>, Chunyu Lin, Lixin Liao, Yao Zhao, Weiyao Lin<br />
					   International Conference on Computer Vision (<strong>ICCV</strong>), 2021<br />
					   <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Liao_Multi-Level_Curriculum_for_Training_a_Distortion-Aware_Barrel_Distortion_Rectification_Model_ICCV_2021_paper.pdf">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/ICCV21-ROP.png" width="240" height="130">					
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">					
					  <strong>Towards Complete Scene and Regular Shape for Distortion Rectification by Curve-Aware Extrapolation</strong><br />
					  <strong>Kang Liao</strong>, Chunyu Lin, Yunchao Wei, Feng Li, Shangrong Yang, Yao Zhao<br />
					   International Conference on Computer Vision (<strong>ICCV</strong>), 2021<br />
					   <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Liao_Towards_Complete_Scene_and_Regular_Shape_for_Distortion_Rectification_by_ICCV_2021_paper.pdf">[PDF]</a>
					</p>
				  </div>
				</div>
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/CVPR21-PCN.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Appearance Flow-based Progressively Complementary Network for Distortion Rectification</strong><br />
					  Shangrong Yang*, Chunyu Lin*, <strong>Kang Liao</strong>*, Chunjie Zhang, Yao Zhao<br />
					   IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2021 <br />
					   (*Equal contribution. Personal efforts: idea - 50%, paper revision - 30%, rebuttal - 90%)<br />
					   <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Progressively_Complementary_Network_for_Fisheye_Image_Rectification_Using_Appearance_Flow_CVPR_2021_paper.pdf">[PDF]</a>
					   <a href="https://github.com/uof1745-cmd/PCN">[Github]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TIP21-ordinal.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>A Deep Ordinal Distortion Estimation Approach for Distortion Rectification</strong><br />
					  <strong>Kang Liao</strong>, Chunyu Lin, Yao Zhao<br />
					   IEEE Transactions on Image Processing (<strong>IEEE TIP</strong>), 2021<br />
					   <a href="https://ieeexplore.ieee.org/document/9366359">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TITS21-PLIN2.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Pseudo-LiDAR Point Cloud Interpolation Based on 3D Motion Representation and Spatial Supervision</strong><br />
					  Haojie Liu*, <strong>Kang Liao</strong>*, Chunyu Lin, Yao Zhao, Yulan Guo<br />
					   IEEE Transactions on Intelligent Transportation Systems (<strong>IEEE TITS</strong>), 2021 <br />
					   (*Equal contribution. Personal efforts: idea - 90%, paper writing - 40%, rebuttal - 90%)<br />
					   <a href="https://ieeexplore.ieee.org/document/9352507">[PDF]</a>
					   <a href="https://github.com/Chunyu-Lin-bjtu/haojieliu_PLIN_Based_on_3D_Motion_Representation_and_Spatial_Super">[Github]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TIP21-unsupervised.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Unsupervised Deep Image Stitching: Reconstructing Stitched Features to Images</strong><br />
					  Lang Nie, Chunyu Lin, <strong>Kang Liao</strong>, Shuaicheng Liu, Yao Zhao<br />
					   IEEE Transactions on Image Processing (<strong>IEEE TIP</strong>), 2021<br />
					   <a href="https://ieeexplore.ieee.org/document/9472883">[PDF]</a>
					   <a href="https://github.com/nie-lang/UnsupervisedDeepImageStitching">[Github]</a>
					   <a href="https://zhuanlan.zhihu.com/p/386863945">[Chinese Blog]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TCSVT21-homo.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Depth-Aware Multi-Grid Deep Homography Estimation with Contextual Correlation</strong><br />
					  Lang Nie, Chunyu Lin, <strong>Kang Liao</strong>, Shuaicheng Liu, Yao Zhao<br />
					   IEEE Transactions on Circuits and Systems for Video Technology (<strong>IEEE TCSVT</strong>), 2021<br />
					   <a href="https://arxiv.org/pdf/2107.02524.pdf">[PDF]</a>
					   <a href="https://github.com/nie-lang/Multi-Grid-Deep-Homography">[Github]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TCSVT21-revisiting.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Revisiting Radial Distortion Rectification in Polar-coordinates: A New and Efficient Learning Perspective</strong><br />
					  Keyao Zhao, Chunyu Lin, <strong>Kang Liao</strong>, Shangrong Yang, Yao Zhao<br />
					   IEEE Transactions on Circuits and Systems for Video Technology (<strong>IEEE TCSVT</strong>), 2021<br />
					   <a href="https://ieeexplore.ieee.org/abstract/document/9567670">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/Neuro21-joint.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Joint Distortion Rectification and Super-Resolution for Self-Driving Scene Perception</strong><br />
					  Keyao Zhao, <strong>Kang Liao</strong>, Chunyu Lin, Yao Zhao<br />
					   Neurocomputing, 2021<br />
					   <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231220320270">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/Neuro21-mag.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Pseudo-LiDAR Point Cloud Magnification</strong><br />
					  Chunlan Zhang, <strong>Kang Liao</strong>, Chunyu Lin, Yao Zhao<br />
					   Neurocomputing, 2021<br />
					   <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231220314569?dgcid=rss_sd_all">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>



