<head>
	<style>
		body{
			color: #333;
		}
		#container{
			min-width: 1000px;
			width: 1000px;
/*			overflow: auto;
*/			margin: 50px auto;padding: 30px;
			/*zoom: 1;*/
*//*			border: 1px solid #ccc;background: #fc9;color: #fff;
*/		}
		#left{
			float: left;
			width: 400px;
			height: 230px;
			margin-left: 0px;
		}
		#right{
			float: left;
			width: auto;
			margin-left: 50px;
		}
		#name{
			font-size: 22.0pt;
		    mso-bidi-font-size: 24.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		        font-weight: bold;
		}
		#info{
		    font-size: 16.0pt;
		    mso-bidi-font-size: 17.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    margin-top: 30px;
		    margin-left: 5px;
		    margin-bottom: 10px;
		    
		}
		.clear{clear:both; height: 0; line-height: 0; font-size: 0}
		.Bio{
			font-size:16.0pt;
			mso-bidi-font-size:17.0pt;
			line-height:150%;
			font-family:Times;
			mso-bidi-font-family:Lato-Regular;
			text-align: justify;
		}
		span.SpellE {
		    mso-style-name: "";
		    mso-spl-e: yes;
		}
		span.Title{
			    font-size: 22.0pt;
			    mso-bidi-font-size: 17.0pt;
			    font-family: Times;
			    mso-bidi-font-family: Lato-Regular;
			    font: bold;
			    margin-top: 10px;
		}
		div.section{
			padding-top: 30px;
		}
		
		div.sub-left{
			float: left;
			width: 250px;
						
		}
		div.sub-left img{
			vertical-align: middle;
			horizontal-align: middle;
			margin-top: 10px;
		}
		
		div.sub-left span{
			height: 100%;
			display: inline-block;
			vertical-align: top;
						
		}
		div.sub-right{
			float: left;
			width: 700px;			
		}
		.paper{
			overflow: auto;
			zoom:1;
			padding-bottom: 0px;
			min-height: 150px;

		}
		.paperTitle{
			font-size:14.0pt;
			mso-bidi-font-size:18.0pt;
			font-family:Times;
			mso-bidi-font-family:Times;
			margin-top: 10px;
			margin-bottom: 10px;
			font-weight: bold;
		}
		.paperName,.paperPub{
		    font-size: 12.0pt;
		    mso-bidi-font-size: 13.0pt;		    
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    line-height:150%;
		}
		.link{
		    font-size: 12.0pt;
		    mso-bidi-font-size: 13.0pt;
		    font-family: Times;
		    mso-bidi-font-family: Times;
		    margin-top: 10px;
		    margin-bottom: 0px;
		}
		.special{
		    margin-top: 0in;
		    margin-bottom: 0in;
		    margin-left: -.9pt;
		    margin-bottom: .0001pt;
		    text-indent: .9pt;
		    mso-pagination: none;
		    tab-stops: 13.75in;
		    mso-layout-grid-align: none;
		    text-autospace: none;
		}
		.long div.sub-left, .long div.sub-right{
			height: 300px;
			width: 950px;

		}
		.short div.sub-left, .short div.sub-right{
			height:160px;

		}
		div.sub-left,div.sub-right{
			height:200px;

		}
	</style>
</head>


<h3>
	<a name='publications'></a> Publications
</h3>

<h4>
	<a name='pre'></a> Preprint
</h4>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/panoformer.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>PanoFormer: Panorama Transformer for Indoor 360° Depth Estimation</strong><br />
					   Zhijie Shen, Chunyu Lin, <strong>Kang Liao</strong>, Lang Nie, Zishuo Zheng, Yao Zhao<br />
					   <a href="https://arxiv.org/pdf/2203.09283.pdf">[arXiv]</a>
					   <a href="">[Github]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/cylinpainting.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Cylin-Painting: Seamless 360° Panoramic Image Outpainting and Beyond with Cylinder-Style Convolutions</strong><br />
					   <strong>Kang Liao</strong>, Xiangyu Xu, Chunyu Lin, Wenqi Ren, Yunchao Wei, Yao Zhao<br />
					   <a href="https://arxiv.org/pdf/2204.08563.pdf">[arXiv]</a>
					   <a href="https://github.com/KangLiao929/Cylin-Painting">[Github]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/reliable-op.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Towards Reliable Image Outpainting: Learning Structure-Aware Multimodal Fusion with Depth Guidance</strong><br />
					   Lei Zhang, <strong>Kang Liao</strong>, Chunyu Lin, Yao Zhao<br />
					   <a href="https://arxiv.org/pdf/2204.05543.pdf">[arXiv]</a>
					   <a href="">[Github]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

<h4>
	<a name='2022'></a> 2022
</h4>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/CVPR22-Rectangling.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Deep Rectangling for Image Stitching: A Learning Baseline</strong><br />
					   Lang Nie, Chunyu Lin, <strong>Kang Liao</strong>, Shuaicheng Liu, Yao Zhao<br />
					   IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>, <strong><font color="red">Oral</font></strong>), 2022<br />
					   <a href="https://arxiv.org/pdf/2203.03831.pdf">[PDF]</a>
					   <a href="https://github.com/nie-lang/DeepRectangling">[Github]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/VR22-Sivs.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>SivsFormer: Parallax-Aware Transformers for Single-image-based View Synthesis</strong><br />
					   Chunlan Zhang, Chunyu Lin, <strong>Kang Liao</strong>, Lang Nie, Yao Zhao<br />
					   IEEE Conference on Virtual Reality and 3D User Interfaces (<strong>IEEE VR</strong>), 2022<br />
					   <a href="https://ieeexplore.ieee.org/document/9756742">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

<h4>
	<a name='2021'></a> 2021
</h4>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/ICCV21-curriculum.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Multi-Level Curriculum for Training A Distortion-Aware Barrel Distortion Rectification Model</strong><br />
					  <strong>Kang Liao</strong>, Chunyu Lin, Lixin Liao, Yao Zhao, Weiyao Lin<br />
					   International Conference on Computer Vision (<strong>ICCV</strong>), 2021<br />
					   <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Liao_Multi-Level_Curriculum_for_Training_a_Distortion-Aware_Barrel_Distortion_Rectification_Model_ICCV_2021_paper.pdf">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/ICCV21-ROP.png" width="240" height="130">					
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">					
					  <strong>Towards Complete Scene and Regular Shape for Distortion Rectification by Curve-Aware Extrapolation</strong><br />
					  <strong>Kang Liao</strong>, Chunyu Lin, Yunchao Wei, Feng Li, Shangrong Yang, Yao Zhao<br />
					   International Conference on Computer Vision (<strong>ICCV</strong>), 2021<br />
					   <a href="https://openaccess.thecvf.com/content/ICCV2021/papers/Liao_Towards_Complete_Scene_and_Regular_Shape_for_Distortion_Rectification_by_ICCV_2021_paper.pdf">[PDF]</a>
					</p>
				  </div>
				</div>
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/CVPR21-PCN.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Appearance Flow-based Progressively Complementary Network for Distortion Rectification</strong><br />
					  Shangrong Yang*, Chunyu Lin*, <strong>Kang Liao</strong>*, Chunjie Zhang, Yao Zhao<br />
					   IEEE/CVF Conference on Computer Vision and Pattern Recognition (<strong>CVPR</strong>), 2021 <br />
					   (*Equal contribution. Personal efforts: idea - 50%, paper revision - 30%, rebuttal - 90%)<br />
					   <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Yang_Progressively_Complementary_Network_for_Fisheye_Image_Rectification_Using_Appearance_Flow_CVPR_2021_paper.pdf">[PDF]</a>
					   <a href="https://github.com/uof1745-cmd/PCN">[Github]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TIP21-ordinal.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>A Deep Ordinal Distortion Estimation Approach for Distortion Rectification</strong><br />
					  <strong>Kang Liao</strong>, Chunyu Lin, Yao Zhao<br />
					   IEEE Transactions on Image Processing (<strong>IEEE TIP</strong>), 2021<br />
					   <a href="https://ieeexplore.ieee.org/document/9366359">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TITS21-PLIN2.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Pseudo-LiDAR Point Cloud Interpolation Based on 3D Motion Representation and Spatial Supervision</strong><br />
					  Haojie Liu*, <strong>Kang Liao</strong>*, Chunyu Lin, Yao Zhao, Yulan Guo<br />
					   IEEE Transactions on Intelligent Transportation Systems (<strong>IEEE TITS</strong>), 2021 <br />
					   (*Equal contribution. Personal efforts: idea - 90%, paper writing - 40%, rebuttal - 90%)<br />
					   <a href="https://ieeexplore.ieee.org/document/9352507">[PDF]</a>
					   <a href="https://github.com/Chunyu-Lin-bjtu/haojieliu_PLIN_Based_on_3D_Motion_Representation_and_Spatial_Super">[Github]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TIP21-unsupervised.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Unsupervised Deep Image Stitching: Reconstructing Stitched Features to Images</strong><br />
					  Lang Nie, Chunyu Lin, <strong>Kang Liao</strong>, Shuaicheng Liu, Yao Zhao<br />
					   IEEE Transactions on Image Processing (<strong>IEEE TIP</strong>), 2021<br />
					   <a href="https://ieeexplore.ieee.org/document/9472883">[PDF]</a>
					   <a href="https://github.com/nie-lang/UnsupervisedDeepImageStitching">[Github]</a>
					   <a href="https://zhuanlan.zhihu.com/p/386863945">[Chinese Blog]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TCSVT21-homo.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Depth-Aware Multi-Grid Deep Homography Estimation with Contextual Correlation</strong><br />
					  Lang Nie, Chunyu Lin, <strong>Kang Liao</strong>, Shuaicheng Liu, Yao Zhao<br />
					   IEEE Transactions on Circuits and Systems for Video Technology (<strong>IEEE TCSVT</strong>), 2021<br />
					   <a href="https://arxiv.org/pdf/2107.02524.pdf">[PDF]</a>
					   <a href="https://github.com/nie-lang/Multi-Grid-Deep-Homography">[Github]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TCSVT21-revisiting.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Revisiting Radial Distortion Rectification in Polar-coordinates: A New and Efficient Learning Perspective</strong><br />
					  Keyao Zhao, Chunyu Lin, <strong>Kang Liao</strong>, Shangrong Yang, Yao Zhao<br />
					   IEEE Transactions on Circuits and Systems for Video Technology (<strong>IEEE TCSVT</strong>), 2021<br />
					   <a href="https://ieeexplore.ieee.org/abstract/document/9567670">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/Neuro21-joint.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Joint Distortion Rectification and Super-Resolution for Self-Driving Scene Perception</strong><br />
					  Keyao Zhao, <strong>Kang Liao</strong>, Chunyu Lin, Yao Zhao<br />
					   Neurocomputing, 2021<br />
					   <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231220320270">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/Neuro21-mag.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Pseudo-LiDAR Point Cloud Magnification</strong><br />
					  Chunlan Zhang, <strong>Kang Liao</strong>, Chunyu Lin, Yao Zhao<br />
					   Neurocomputing, 2021<br />
					   <a href="https://www.sciencedirect.com/science/article/abs/pii/S0925231220314569?dgcid=rss_sd_all">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


<h4>
	<a name='2020'></a> 2020
</h4>


		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TIP20-DDM.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Model-Free Distortion Rectification Framework Bridged by Distortion Distribution Map</strong><br />
					  <strong>Kang Liao</strong>, Chunyu Lin, Yao Zhao, Mai Xu<br />
					   IEEE Transactions on Image Processing (<strong>IEEE TIP</strong>), 2020<br />
					   <a href="https://ieeexplore.ieee.org/document/8962122">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/JSTSP20-OIDC.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>OIDC-Net: Omnidirectional Image Distortion Correction via Coarse-to-fine Region Attention</strong><br />
					  <strong>Kang Liao</strong>, Chunyu Lin, Yao Zhao, Moncef Gabbouj<br />
					   IEEE Journal of Selected Topics in Signal Processing (<strong>IEEE JSTSP</strong>), 2020<br />
					   <a href="https://ieeexplore.ieee.org/document/8910406">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>
	

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/JVCIR20-view-free.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>A view-free image stitching network based on global homography</strong><br />
					  Lang Nie, Chunyu Lin, <strong>Kang Liao</strong>, Meiqin Liu, Yao Zhao<br />
					   Journal of Visual Communication and Image Representation (<strong>JVCIR</strong>), 2020<br />
					   <a href="https://www.sciencedirect.com/science/article/abs/pii/S1047320320301784">[PDF]</a>
					   <a href="https://github.com/nie-lang/DeepImageStitching-1.0">[Github]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/VR20-SR.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Panoramic Image Quality-Enhancement by Fusing Neural Textures of the Adaptive Initial Viewport</strong><br />
					  Shiyuan Li, Chunyu Lin, <strong>Kang Liao</strong>, Yao Zhao, Xue Zhang<br />
					   IEEE Virtual Reality Workshop (<strong>IEEE VR</strong>), 2020<br />
					   <a href="https://ieeexplore.ieee.org/document/9090422">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/NCIG20-point.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Scene Viewpoint Offset to Improve Point Cloud Segmentation</strong><br />
					  Yang Zheng, <strong>Kang Liao</strong>, Chunyu Lin, Yao Zhao<br />
					   National Conference on Image and Graphics (<strong>NCIG</strong>), 2020<br />
					   <a href="">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>


<h4>
	<a name='2019'></a> 2019
</h4>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/TCSVT19-dynamic.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>Distortion Rectification from Static to Dynamic: A Distortion Sequence Construction Perspective</strong><br />
					  <strong>Kang Liao</strong>, Chunyu Lin, Yao Zhao, Moncef Gabbouj<br />
					   IEEE Transactions on Circuits and Systems for Video Technology (<strong>IEEE TCSVT</strong>), 2019<br />
					   <a href="https://ieeexplore.ieee.org/document/8926530">[PDF]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

		<div class="paper short">
				<div class="sub-left">
					<span></span>
					<img src="assets/images/CSVT19-DRGAN.png" width="240" height="130">
				</div>
				<div class="sub-right">
				<div class="media">
				  <div class="media-body">
					<p class="media-heading">
					  <strong>DR-GAN: Automatic Radial Distortion Rectification Using Conditional GAN in Real-Time</strong><br />
					  <strong>Kang Liao</strong>, Chunyu Lin, Yao Zhao, Moncef Gabbouj<br />
					   IEEE Transactions on Circuits and Systems for Video Technology (<strong>IEEE TCSVT</strong>), 2019<br />
					   <a href="https://ieeexplore.ieee.org/document/8636975">[PDF]</a>
					   <a href="https://github.com/KangLiao929/DR-GAN">[Github]</a>
					</p>
				  </div>
				</div>	
				</div>
			</div>

